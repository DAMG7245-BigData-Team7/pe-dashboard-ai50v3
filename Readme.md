# Project ORBIT ‚Äî PE Due Diligence Agentic System
## Agentification & MCP Integration for PE Dashboard (DAMG7245 - Assignment 5)

[![Tests](https://img.shields.io/badge/tests-37%2F37%20passing-brightgreen)](tests/)
[![Python](https://img.shields.io/badge/python-3.13-blue)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)

An intelligent, production-ready PE due diligence system powered by LangChain agents, LangGraph workflows, and the Model Context Protocol (MCP).

## üéØ Overview

Project ORBIT transforms traditional PE dashboard generation into an **agentic, automated workflow** with:

- ü§ñ **LangChain Agents**: Supervisor, Planner, and Evaluator agents with ReAct reasoning
- üîÑ **LangGraph Workflows**: Graph-based orchestration with conditional branching
- üåê **MCP Server**: Standardized tool/resource/prompt exposure via HTTP
- üö® **HITL Integration**: Human-in-the-loop approval for high-risk companies
- üìä **Airflow DAGs**: Scheduled workflows for initial load, daily updates, and agentic dashboards
- üê≥ **Docker Deployment**: Full containerization with docker-compose

---

## üèóÔ∏è System Architecture

```

```

---

## ‚ú® Key Features

### Phase 1 - Agent Infrastructure (Labs 12-13) ‚úÖ
- 3 core agent tools with async support
- Pydantic models for structured I/O
- Supervisor Agent with ReAct pattern
- Structured JSON logging with correlation IDs
- 10 unit tests (100% passing)

### Phase 2 - MCP Integration (Labs 14-15) ‚úÖ
- MCP Server with 6 HTTP endpoints
- Dashboard generation tools (structured + RAG)
- Company resources and prompt templates
- Docker support with health checks
- 11 integration tests (100% passing)

### Phase 3 - Advanced Workflows (Labs 16-18) ‚úÖ
- LangGraph StateGraph with 7 nodes
- Conditional branching (HITL vs Auto-Approve)
- Risk keyword detection (11 keywords)
- Interactive CLI pause/resume for HITL
- 16 workflow tests (100% passing)

### Phase 4 - Orchestration & Deployment ‚úÖ
- 3 Airflow DAGs (initial load, daily update, agentic dashboard)
- Docker Compose for full stack deployment
- Configuration management (YAML + .env)
- Production-ready logging and monitoring

---

## üöÄ Quick Start

### Prerequisites

- Python 3.13+
- Docker & Docker Compose (optional)
- OpenAI API Key
- Pinecone API Key (optional)

### Option 1: Local Setup

```bash
# 1. Clone repository
git clone <your-repo-url>
cd pe-dashboard-ai50-v3

# 2. Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 5. Run MCP Server (Terminal 1)
uvicorn src.server.mcp_server:app --port 9000

# 6. Run Workflow (Terminal 2)
PYTHONPATH=. python3 src/workflows/due_diligence_graph.py anthropic

# 7. Run Tests
PYTHONPATH=. pytest -v
```

### Option 2: Docker Setup

```bash
# 1. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 2. Start all services
docker-compose up --build

# 3. Check health
curl http://localhost:9000/health

# 4. Stop services
docker-compose down
```

---

## üìã Usage Examples

### Run Due Diligence Workflow

```bash
# Interactive mode (requires human approval for risky companies)
PYTHONPATH=. HITL_AUTO_APPROVE=false python3 src/workflows/due_diligence_graph.py anthropic

# Auto-approve mode (for automation)
PYTHONPATH=. HITL_AUTO_APPROVE=true python3 src/workflows/due_diligence_graph.py openai
```

### Call MCP Server Directly

```bash
# Health check
curl http://localhost:9000/health

# Get company list
curl http://localhost:9000/resource/ai50/companies

# Generate dashboard
curl -X POST http://localhost:9000/tool/generate_structured_dashboard \
  -H "Content-Type: application/json" \
  -d '{"company_id": "anthropic"}'
```

### Run Airflow DAGs

```bash
# Trigger initial load
airflow dags trigger orbit_initial_load

# Trigger agentic dashboard generation
airflow dags trigger orbit_agentic_dashboard

# Check status
airflow dags state orbit_agentic_dashboard <execution_date>
```

---

## üß™ Testing

```bash
# Run all tests
PYTHONPATH=. pytest -v

# Run specific test suite
PYTHONPATH=. pytest tests/test_tools.py -v
PYTHONPATH=. pytest tests/test_mcpserver.py -v
PYTHONPATH=. pytest tests/test_workflow_branches.py -v

# Run with coverage
PYTHONPATH=. pytest --cov=src --cov-report=html
```

**Test Results**: ‚úÖ 37/37 tests passing (100%)

---

## üìÅ Project Structure

```

```

---

## üîß Configuration

### Environment Variables (.env)

```bash
# API Keys
OPENAI_API_KEY=your_key_here
PINECONE_API_KEY=your_key_here

# MCP Server
MCP_BASE_URL=http://localhost:9000
MCP_PORT=9000

# Agent Config
AGENT_MODEL=gpt-4o-mini
AGENT_TEMPERATURE=0

# HITL Config
HITL_AUTO_APPROVE=false  # Set to true for automation
```

### Application Settings (config/settings.yaml)

Copy `config/settings_example.yaml` to `config/settings.yaml` and customize:

- API endpoints and keys
- Workflow configuration
- Risk detection keywords
- Logging levels
- Performance tuning

---

## üìä Workflow Execution

### No-Risk Path (Auto-Approve)

```
START ‚Üí Planner ‚Üí Data Generator ‚Üí Evaluator ‚Üí Risk Detector
        ‚Üí Auto-Approve ‚Üí Final Decision ‚Üí END

Duration: ~2-5 seconds
```

### Risk Path (HITL Required)

```
START ‚Üí Planner ‚Üí Data Generator ‚Üí Evaluator ‚Üí Risk Detector
        ‚Üí HITL (Human Approval) ‚Üí Final Decision ‚Üí END

Duration: Variable (depends on human response time)
```

---

## üêõ Troubleshooting

### MCP Server Not Starting

```bash
# Check if port 9000 is in use
lsof -i :9000

# Kill process using port
kill -9 <PID>

# Restart MCP server
uvicorn src.server.mcp_server:app --port 9000
```

### Workflow Hangs During HITL

```bash
# Set auto-approve mode
export HITL_AUTO_APPROVE=true

# Or run with environment variable
HITL_AUTO_APPROVE=true python3 src/workflows/due_diligence_graph.py anthropic
```

### Tests Failing

```bash
# Ensure PYTHONPATH is set
export PYTHONPATH=.

# Set HITL auto-approve for tests
export HITL_AUTO_APPROVE=true

# Run tests
pytest -v
```

---

## üìö Documentation

- [Phase 1 Complete](PHASE1_COMPLETE.md) - Agent Infrastructure & Tools
- [Phase 2 Complete](PHASE2_COMPLETE.md) - MCP Server Integration
- [Phase 3 Complete](PHASE3_COMPLETE.md) - Advanced Workflows
- [Phase 4 Complete](PHASE4_COMPLETE.md) - Orchestration & Deployment
- [Workflow Graph](docs/WORKFLOW_GRAPH.md) - LangGraph workflow docs
- [ReAct Trace Example](docs/REACT_TRACE_EXAMPLE.md) - ReAct pattern demo
- [System Architecture](docs/SYSTEM_ARCHITECTURE.md) - Architecture overview

---

## üìà Metrics & Performance

- **Total Lines of Code**: ~5,700 lines
- **Test Coverage**: 37 tests, 100% passing
- **MCP Endpoints**: 6 endpoints
- **Workflow Nodes**: 7 nodes
- **Risk Keywords**: 11 monitored keywords
- **Airflow DAGs**: 3 DAGs

---

## ü§ù Contributing

This is an academic project for DAMG7245. For questions or issues, please contact the course staff.

---

## üìÑ License

MIT License - See [LICENSE](LICENSE) for details

---

## üë• Team

- **Course**: DAMG7245 - Big Data Systems & Intelligence Analytics
- **Assignment**: Assignment 5 - Project ORBIT Part 2
- **Institution**: Northeastern University

---

